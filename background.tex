\chapter{Background}\label{background}

This section provides a brief high-level introduction to basic concepts used in
the rest of the dissertation.

\section{Static typing}
\label{static-typing}

% Define static typing

% Discipline of prescribing valid programs from invalid ones

Programmers typically do not write programs by simply manipulating bits in the
computer's memory: most languages offer abstraction mechanisms that let their
users reason at a higher level.  One such high-level abstraction is the notion
of a \define{data type}.  A programmer will want to manipulate structured data
such as numbers, Boolean values, or compound values made out of different values
organized together in some fashion.  They will then use, and possibly define, a
set of operations to work on values from different data types.  Those operations
might sometimes be entirely oblivious to what data type they are manipulating,
but frequently, they will expect some properties out of their input values, and
provide some properties for their output values.

A \define{type system} is a mechanism that enforces some discipline about the
proper use of values in a program according to a set of typing rules.
\define{Typing rules} usually ascribe a type to every value of a program, and
prescribe the typed contexts within which a value of a given type may be used.
A \define{type} can be anything from a simple classification of values according
to their nature (for instance, distinguishing numbers from functions), to more
semantic rules that may sometimes be defined by the user of the language.  In
this dissertation, we will use the notation \mintinline{coq}{t : τ} to indicate
that a term \coqinline{t} has type \coqinline{τ}.

A \define{static} typing discipline allows the programming environment (be it a
compiler, an interpreter, or any other language tool) to reject programs
\textbf{before they run}.  On the opposite, a \define{dynamic} typing discipline
enforces its typing discipline on-the-fly, as programs execute.  This allows
more programs to execute, as long as their execution path does not encounter a
typing violation.  On the other hand, this provides less safety, as latent
errors in the programs stay unnoticed until an execution path triggers them.  In
this dissertation, we will focus solely on static typing disciplines.

There can be several reasons for why one might want to reject a program, whether
statically or dynamically.  The simplest case is a breach of expectation between
a value and the context into which it is passed: this is usually called a
\define{type error}.  For instance, a function declared to expect a number input
might not be allowed to receive a string instead.

Another, less obvious, unfortunate reason for rejecting a syntactically-valid,
semantically-valid program, is that the static enforcement of typing rules
cannot, in general, be complete.  For instance, dependent type systems (covered
in Section~\ref{dependent-types}) cannot safely ensure their typing discipline
in the presence of arbitrary recursion.  In order to reject all \define{unsafe}
programs before they are run, they must restrict the programs they allow to some
conservative subsets of all \define{safe} programs.

While the idea of preventing programmers from running syntactically-valid
programs might seem like a nuisance, it provides at least two benefits.  From
the programmer's point of view, a disciplined use of the type system can help
them catch, before their program is run, conditions that would make the program
crash were it to be executed.  These conditions can often be indicated at
locations close to the source of error.  The typing discipline can also provide
information that can be leveraged as documentation, or in order to perform code
analyses and transformations that would be intractable or unsafe without types.

Strong typing disciplines can even benefit the programmer tenfold, by providing
means of tracking security properties~\mycite{volpano1997type}, resource usage
and sharing\mycite{naden2012type}, dimensions of
units-of-measure~\mycite{kennedy1994dimension}, etc.

\section{Dependent types}
\label{dependent-types}

This dissertation will mostly focus on \define{dependent} type systems.  A
\define{dependent} type is a type whose definition depends on a program value.
Non-dependent type systems can only express lightweight relationships between
the input and output of functions, as well as lightweight constraints on what
these inputs and outputs may be.  In a dependent type system, one can express
such types as \textit{the type of functions that take a number and return a
larger number}, or \textit{the type of positive numbers that are less than 256}.
In order to express these, one must be able to mention in the type, either
concrete values like \coqinline{256}, or program values like the input value of
the function.

In order to define functions whose output type depend on the value of their
input, dependent type systems must have a \define{type former} (i.e.\ a
syntactic construct) for \define{dependent functions}~\footnotemark.  In the
literature, the type of functions which accept an input value \coqinline{a} of
type \coqinline{A}, and return an output value of type \coqinline{B(a)} (where
\coqinline{B} is a family of types indexed by values of type \coqinline{A}), is
often written as either:

\footnotetext{ \textit{Dependent functions} are sometimes referred to as
\textit{dependent products} in the literature.  Unfortunately, the similar but
different concept of a \textit{dependent pair} is sometimes referred to as
either a \textit{dependent sum} or, confusingly, a \textit{dependent product}.
Since both views are reasonable, and in order to avoid confusion, we will
strictly adhere to the unambiguous names of \textit{dependent function type} and
\textit{dependent pair type} in this dissertation. }

% Pygments/minted put annoying boxes on Unicode because the Coq lexer is stupid
\makeatletter
\expandafter\def\csname PYGlovelace@tok@err\endcsname{\def\PYGlovelace@bc##1{\textcolor[rgb]{0.0,0.0,0.0}{##1}}}
\makeatother

\begin{itemize}

  \item \coqinline{(a : A) → B(a)} % $(a : A) \rightarrow B(a)$

  \item \coqinline{∀(a : A), B(a)}
  % $\forall (a : A), B(a)$
        ~\footnote{The $\forall$ symbol is pronounced ``for all''.}

  \item \coqinline{Π(a : A) → B(a)} % $\Pi (a : A) \rightarrow B(a)$
        ~\footnote{The $\Pi$ symbol may also be pronounced ``for all'' in such context, or ``pi''.}

\end{itemize}

\noindent
We will tend to use the latter, and refer to those types as $\Pi$-types.

When a dependent function takes several arguments, we will group them all into a
single $\Pi$, and coalesce successive values of the same type in groups under
the same set of parentheses.  In practice, this means that the types:

\noindent
\coqinline{Π(a : X) (b c : Y) (d : Z) → R(a, b, c, d)}

\noindent
and

\noindent
\coqinline{Π(a : X) → Π(b : Y) → Π(c : Y) → Π(d : Z) → R(a, b, c, d)}

\noindent
are syntactically equivalent, and we will favor the former (shorter) syntax.

% Introduce Π-telescopes

Nested $\Pi$-types, that is, ones that appear to the right of the arrow of an
enclosing $\Pi$-type, can depend on the values of the previously quantified
variables.  We call a \define{$\Pi$-telescope} any sequence of $\Pi$-types
\emph{directly} nested within one another.  We can summarize them in a list of
bindings and their types, where each type is allowed to, but does not have to,
depend on previous bindings.  For instance, the type:

\noindent
\coqinline{Π(a : X) (b : Y(a)) (c : Z(a)) → R(a, b, c)}

\noindent
contains a telescope of three bindings (namely, \coqinline{a}, \coqinline{b},
and \coqinline{c}), and the type of the last two bindings depend on the value of
the first binding.

Dependent types may also manifest themselves in other forms depending on the
constructs of the language that integrates them.  For instance, languages with
records may allow dependent records, where the type of some fields may depend on
the value of some other fields.  A typical example is the packing of a plain
data structure with extra properties that we want it to have, for instance,
ensuring the binary-search-tree (or \define{BST}) property of a binary tree:

\begin{minted}{coq}
Inductive BinarySearchTree a := MakeBinarySearchTree
  { tree  : BinaryTree a
  , isBST : IsBinarySearchTree tree
  }.
\end{minted}

For the scope of this dissertation, we do not handle such features explicitly,
but believe that the constructions we present are amenable to the introduction
of those features: the simplest flavor of dependent records can be simulated
using a combination of constructs we cover.

\section{Proof assistants}

Our first contribution focuses mostly on programs built using a \define{proof
assistant}.  A proof assistant is a software tool allowing a user to define
mathematical structures, with their axioms and rules, and carry mechanized
proofs of properties of those structures.  By \define{mechanized}, we mean that
the software has the ability to check that a proof is correct, with respect to a
set of rules.  Many proof assistants rely on the Curry-Howard
isomorphism~\cite{howard1980formulae}, bridging the gap between formal logic and
typed programming.  In those systems, logical propositions can be readily
expressed as types, in the same formal system within which programs can be
defined.  Proofs built this way are essentially programs, whose computational
content is often less interesting than the fact that they are well-typed, and as
such, are \define{witnesses} for the type/proposition they inhabit.

Proof assistants come in a large variety, both from a theoretical point of view,
and in terms of user experience.  On the theory side, there are many logical
systems of interest, and different proof assistants tend to focus on some
classes of those.  For instance, the \Coq{} proof assistant focuses, by default,
on an intuitionistic fragment of the calculus of (co)-inductive constructions,
or \Language{CoC}, but allows itself to be extended with axioms to support
classical reasoning, or extensional notions of equality, if needed.

A proof assistant is typically composed of several interacting pieces:

\begin{itemize}

  \item a \emph{programming language}, allowing the user to define programs that
they wish to execute and/or reason about formally,

  \item a \emph{specification language}, allowing the user to define properties
of programs, or general theorems, that they wish to prove,

  \item a \emph{proof language}, allowing the user to build those proofs.

\end{itemize}

Note that these languages need not be different from one another, and several
languages can help fulfill one of those purposes.  For instance, in the \Coq{}
proof assistant, the programming language and the specification language are the
same language, called \Gallina{}, and the proof language can be either
\Gallina{} itself, or a proof-building scripting language called \Ltac{}.

Learning to use such a proof assistant therefore requires familiarizing oneself
with not only a programming language with a complex type system, but also the
logical foundation of formal proofs, and the idiosyncrasies of the proof
environment of choice.

For the \Coq{} proof assistant, novice users are generally taught to use \Ltac{}
to build proofs, since manually building \Gallina{} terms requires more
expertise and is usually tedious.  An \Ltac{} script is a sequence of commands
(usually called \define{tactics}) directing the proof assistant as to what
logical rules to use in order to progress in building the proof term.  These
tactics include:

\begin{itemize}

  \item \emph{proof-solving tactics}, which attempt to complete a proof
obligation by constructing the complete proof,

  \item \emph{case-splitting tactics}, which break a proof obligation into
several sub-obligations, by using some rule of the formal logic with multiple
antecedents,

  \item \emph{bookkeeping tactics}, which modify the context or the goal of the
current proof obligation, either by adding/removing/reordering/rewriting in
hypotheses, or by performing modifications in the goal.

\end{itemize}

A typical proof can therefore be thought of as a tree, branching on
case-splitting tactics, extending on bookkeeping tactics, and with proof-solving
tactics as leaves.  The proving process is rarely linear: many proofs will
require using concepts such as \emph{case analysis} and \emph{induction} in
order to break down a complex goal into specialized sub-goals that can be solved
separately.  In those sub-cases, one will often need to perform applications and
rewriting using existing theorems.

The \define{application} of a theorem (or a hypothesis) \coqinline{(t : τ)} can
be performed in either a hypothesis or a goal.  To apply it in a hypothesis
\coqinline{(a : α)}:

\begin{itemize}

  \item the type of the applied term, \coqinline{τ}, must reduce to a Π-telescope:

    \coqinline{Π(t1 : τ1) ... (tn : τn) → tr : τr}

  \item the type of the target hypothesis, \coqinline{α}, must be compatible
with of one of the \coqinline{τi} (if there are multiple candidates, the first
such \coqinline{τi} will be considered)

\end{itemize}

It then yields the conclusion of the applied term, \coqinline{τr}, as a
hypothesis, but also adds new obligations for all the other antecedents in the
telescope.  Intuitively, the applied term \coqinline{t} was fully applied, with
formal parameter \coqinline{τi} receiving argument \coqinline{a}, and all other
formal parameters receiving arguments to be determined by solving the new
obligations.  That is, given the context:

\begin{minted}{coq}
A, B, C : Prop
H1 : A → B → C
H2 : B
==================
C
\end{minted}

\noindent applying hypothesis \coqinline{H1} in hypothesis \coqinline{H2} yields
the following two obligations:

\begin{minted}{coq}
(* 1. Hypothesis H2 became the conclusion of H1. *)
A, B, C : Prop
H1 : A → B → C
H2 : C
==================
C
\end{minted}

and:

\begin{minted}{coq}
(* 2. In the original context, one must prove A. *)
A, B, C : Prop
H1 : A → B → C
H2 : B
==================
A
\end{minted}

Conversely, a theorem or hypothesis can be applied to the goal of the current
obligation if its conclusion matches the goal.  It yields an obligation for each
antecedent.  For instance, applying hypothesis \coqinline{H1} from the original
context to the goal would yield the following two obligations:

\begin{minted}{coq}
(* 1. One must prove the first antecedent A. *)
A, B, C : Prop
H1 : A → B → C
H2 : B
==================
A
\end{minted}

and:

\begin{minted}{coq}
(* 2. One must prove the second antecedent B. *)
A, B, C : Prop
H1 : A → B → C
H2 : B
==================
B
\end{minted}

\define{Rewriting} with a theorem or a hypothesis is a similar concept, but for
dealing with equalities (or, more generally, structures that admit equivalence
relations, called \define{setoids}).  We will focus on the simple case of
equalities.  Again, one can either use rewrite in a hypothesis, or over the
goal.  One can rewrite with a theorem or hypothesis as long as its conclusion is
an equality.  The rewriting consists of replacing one side of the equality with
the other side, for a given occurrence.  It is a directed operation, either
replacing the left operand of the binary relation with the right one, or
vice-versa.

For instance, given this original context:

\begin{minted}{coq}
P, Q : ℕ → Prop
x, y, z : ℕ
H1 : Q z → x = y
H2 : P x
==================
P y
\end{minted}

rewriting from left to right with hypothesis \coqinline{H1} in hypothesis
\coqinline{H2} yields the two obligations:

\begin{minted}{coq}
(* 1. x has been replaced with y in H2. *)
P, Q : ℕ → Prop
x, y, z : ℕ
H1 : Q z → x = y
H2 : P y
==================
P y
\end{minted}

and:

\begin{minted}{coq}
(* 2. One must prove the antecedent. *)
P, Q : ℕ → Prop
x, y, z : ℕ
H1 : Q z → x = y
H2 : P x
==================
Q z
\end{minted}

while rewriting from right to left with hypothesis \coqinline{H1} in the goal
yields the two obligations:

\begin{minted}{coq}
(* 1. y has been replaced with x in the goal. *)
P, Q : ℕ → Prop
x, y, z : ℕ
H1 : Q z → x = y
H2 : P x
==================
P x
\end{minted}

and:

\begin{minted}{coq}
(* 2. Again, one must prove the antecedent. *)
P, Q : ℕ → Prop
x, y, z : ℕ
H1 : Q z → x = y
H2 : P x
==================
Q z
\end{minted}

A novice user will need to learn to use these tactics effectively, but will also
need to learn about the families of theorems that are applicable in their proof
development.  For instance, the \Coq{} prelude contains 106 equality theorems,
and importing the module about lists increases this number to 1006.  While there
are facilities to look up theorems of interest based on the shape of their type,
this still lacks in ease of discovery, and it is not rare for one to miss or
re-derive an existing theorem.

\section{Program refactoring}

\begin{itemize}

  \item Define the notion of a refactoring

        \begin{itemize}

          \item Define the notion of semantic preservation

          \item X

          \item X

        \end{itemize}

  \item X

        \begin{itemize}

          \item X

          \item X

          \item X

        \end{itemize}

\end{itemize}
